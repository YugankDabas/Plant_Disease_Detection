{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K55-PDIL9Yg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install colorama"
      ],
      "metadata": {
        "id": "K8M6ZPb1zH9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colorama\n",
        "from colorama import Fore, Style"
      ],
      "metadata": {
        "id": "FPXsvyLDMQ3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XKT2ZBMSMgE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab"
      ],
      "metadata": {
        "id": "kTj5N2s8MtMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"/root/.kaggle/\", exist_ok=True)"
      ],
      "metadata": {
        "id": "L-mx0p3fOWAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/cnn_learn/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download yugankdabas/plant-disease-dataset"
      ],
      "metadata": {
        "id": "CXNLhs-nOci5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip plant-disease-dataset.zip"
      ],
      "metadata": {
        "id": "T7nK6PZdOnrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "8ueYP_eC2Azp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_disease_samples(data_dir, plants=None, num_cols=5):\n",
        "    disease_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])\n",
        "\n",
        "    if plants is not None:\n",
        "        disease_folders = [f for f in disease_folders if any(p in f for p in plants)]\n",
        "\n",
        "    num_diseases = len(disease_folders)\n",
        "    num_rows = (num_diseases + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 4 * num_rows))\n",
        "    axes = axes.flatten() if num_rows > 1 else axes\n",
        "\n",
        "    for i, disease_folder in enumerate(disease_folders):\n",
        "        folder_path = os.path.join(data_dir, disease_folder)\n",
        "\n",
        "        img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if img_files:\n",
        "            img_path = os.path.join(folder_path, random.choice(img_files))\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "            disease_name = disease_folder.replace('_', ' ')\n",
        "\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(disease_name, fontsize=12)\n",
        "            axes[i].axis('off')\n",
        "\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"ðŸŒ¿ Sample images from different plant disease categories:\")\n",
        "display_disease_samples(\"/content/Plant Disease Dataset\")"
      ],
      "metadata": {
        "id": "bjRRdVTVO-6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset class\n",
        "class PlantDiseaseDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for loading plant disease images\"\"\"\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        #load the image and apply transformations\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "vBxSBXC4zyTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchinfo"
      ],
      "metadata": {
        "id": "VnMlcpkj28QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "class PlantDiseaseModel(nn.Module):\n",
        "    \"\"\"Convolutional Neural Network for plant disease classification\"\"\"\n",
        "    def __init__(self, num_classes, dropout_rate=0.5):\n",
        "        super(PlantDiseaseModel, self).__init__()\n",
        "        # Convolutional Block 1\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=\"same\"),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        # Convolutional Block 2\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=\"same\"),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        # Convolutional Block 3\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=\"same\"),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        # Convolutional Block 4\n",
        "        self.conv_block4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=\"same\"),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        # Convolutional Block 5\n",
        "        self.conv_block5 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=\"same\"),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        # Global Average Pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # Fully Connected Layers\n",
        "        self.fc_block = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.conv_block5(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = self.fc_block(x)\n",
        "        return x\n",
        "\n",
        "print(summary(PlantDiseaseModel(15), input_size=(1, 3, 224, 224)))"
      ],
      "metadata": {
        "id": "1tnHceww2mEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#earlystopping for preventing overfitting\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping handler to prevent overfitting\"\"\"\n",
        "    def __init__(self, patience=5, min_delta=0.001, save_path=\"disease_model.pth\"):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.save_path = save_path\n",
        "        self.best_loss = float('inf')\n",
        "        self.counter = 0\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            #save the model\n",
        "            torch.save(model.state_dict(), self.save_path)\n",
        "            print(f\"[INFO] Model checkpoint saved to {self.save_path}\")\n",
        "            return False\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                print(\"[INFO] Early stopping triggered.\")\n",
        "                return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "hFPpBzJM2tCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data loading\n",
        "def load_images(directory_root):\n",
        "    \"\"\"Load images and their labels from directory structure\"\"\"\n",
        "    image_list, label_list = [], []\n",
        "    print(\"[INFO] Loading images...\")\n",
        "\n",
        "    for disease_folder in os.listdir(directory_root):\n",
        "        disease_folder_path = os.path.join(directory_root, disease_folder)\n",
        "        if not os.path.isdir(disease_folder_path):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(disease_folder_path):\n",
        "            if img_name.startswith(\".\"):\n",
        "                continue\n",
        "            img_path = os.path.join(disease_folder_path, img_name)\n",
        "            if img_path.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_list.append(img_path)\n",
        "                label_list.append(disease_folder)\n",
        "\n",
        "    print(\"[INFO] Image loading completed\")\n",
        "    print(f\"Total images: {len(image_list)}\")\n",
        "    return image_list, label_list\n",
        "\n",
        "def prepare_data(directory_root, image_size=(256, 256), batch_size=32, test_size=0.3, valid_ratio=0.5, random_state=42):\n",
        "    \"\"\"Prepare data loaders and label encoder\"\"\"\n",
        "    #loading image and labels\n",
        "    image_paths, labels = load_images(directory_root)\n",
        "\n",
        "    #encoding labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "    #save label encoder for inference\n",
        "    with open('label_encoder.pkl', 'wb') as f:\n",
        "        pickle.dump(label_encoder, f)\n",
        "\n",
        "    #class name for reference\n",
        "    class_names = list(label_encoder.classes_)\n",
        "    with open('class_names.json', 'w') as f:\n",
        "        json.dump(class_names, f)\n",
        "\n",
        "    #train, validation, and test splits\n",
        "    train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "        image_paths, labels_encoded, test_size=test_size, random_state=random_state, stratify=labels_encoded\n",
        "    )\n",
        "    valid_paths, test_paths, valid_labels, test_labels = train_test_split(\n",
        "        temp_paths, temp_labels, test_size=valid_ratio, random_state=random_state, stratify=temp_labels\n",
        "    )\n",
        "\n",
        "    print(f\"Training samples: {len(train_paths)}\")\n",
        "    print(f\"Validation samples: {len(valid_paths)}\")\n",
        "    print(f\"Test samples: {len(test_paths)}\")\n",
        "\n",
        "    #data transformation\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    valid_test_transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    #save image transformation for inference\n",
        "    with open('inference_transform.pkl', 'wb') as f:\n",
        "        pickle.dump(valid_test_transform, f)\n",
        "\n",
        "    #create datasets with appropriate transformations\n",
        "    train_dataset = PlantDiseaseDataset(train_paths, train_labels, transform=train_transform)\n",
        "    valid_dataset = PlantDiseaseDataset(valid_paths, valid_labels, transform=valid_test_transform)\n",
        "    test_dataset = PlantDiseaseDataset(test_paths, test_labels, transform=valid_test_transform)\n",
        "\n",
        "    #create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader, len(class_names)"
      ],
      "metadata": {
        "id": "63ZeNlAt3X2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dataset_distribution(data_dir):\n",
        "    folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])\n",
        "\n",
        "    counts = {}\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        image_count = len([f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        counts[folder] = image_count\n",
        "\n",
        "    plant_data = {}\n",
        "    for folder, count in counts.items():\n",
        "        #extract plant type\n",
        "        if \"__\" in folder:\n",
        "            parts = folder.split(\"__\")\n",
        "            plant = parts[0].replace(\"_\", \" \")\n",
        "        else:\n",
        "            plant = folder.split(\"_\")[0]\n",
        "\n",
        "        #check if healthy or diseased\n",
        "        if \"healthy\" in folder.lower():\n",
        "            status = \"Healthy\"\n",
        "        else:\n",
        "            status = \"Diseased\"\n",
        "\n",
        "        #organize data by plant type and status\n",
        "        if plant not in plant_data:\n",
        "            plant_data[plant] = {\"Healthy\": 0, \"Diseased\": 0}\n",
        "        plant_data[plant][status] += count\n",
        "\n",
        "    #create plot with enhanced styling\n",
        "    plt.style.use('ggplot')\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 10))\n",
        "\n",
        "    # Color palette\n",
        "    healthy_color = '#4CAF50'  # Modern green\n",
        "    diseased_color = '#FF5722'  # Vibrant orange\n",
        "    pie_colors = plt.cm.tab20.colors  # More distinct colors\n",
        "\n",
        "    # Plot 1: Enhanced stacked bar chart\n",
        "    plants = list(plant_data.keys())\n",
        "    healthy_counts = [plant_data[p][\"Healthy\"] for p in plants]\n",
        "    diseased_counts = [plant_data[p][\"Diseased\"] for p in plants]\n",
        "\n",
        "    # Create gradient effect for bars\n",
        "    bar1 = ax1.bar(plants, healthy_counts, label='Healthy',\n",
        "                   color=healthy_color, edgecolor='#2E7D32', linewidth=1.5)\n",
        "    bar2 = ax1.bar(plants, diseased_counts, bottom=healthy_counts,\n",
        "                   label='Diseased', color=diseased_color, edgecolor='#BF360C', linewidth=1.5)\n",
        "\n",
        "    # Enhanced annotations\n",
        "    for i, plant in enumerate(plants):\n",
        "        total = healthy_counts[i] + diseased_counts[i]\n",
        "        ax1.text(i, total + 50, f'{total}', ha='center',\n",
        "                fontsize=10, fontweight='bold', color='#37474F')\n",
        "        # Add percentage labels inside bars\n",
        "        healthy_pct = healthy_counts[i]/total * 100\n",
        "        ax1.text(i, healthy_counts[i]/2, f'{healthy_pct:.1f}%',\n",
        "                ha='center', va='center', color='white', fontsize=9)\n",
        "        diseased_pct = diseased_counts[i]/total * 100\n",
        "        ax1.text(i, healthy_counts[i] + diseased_counts[i]/2, f'{diseased_pct:.1f}%',\n",
        "                ha='center', va='center', color='white', fontsize=9)\n",
        "\n",
        "    ax1.set_title('Healthy vs Diseased Distribution by Plant Type\\n',\n",
        "                 fontsize=16, fontweight='bold', color='#2E4053')\n",
        "    ax1.set_xlabel('Plant Type', fontsize=13, labelpad=15)\n",
        "    ax1.set_ylabel('Number of Images', fontsize=13, labelpad=15)\n",
        "    ax1.tick_params(axis='x', rotation=45, labelsize=11)\n",
        "    ax1.legend(frameon=True, shadow=True, fontsize=12)\n",
        "\n",
        "    # Add subtle grid\n",
        "    ax1.yaxis.grid(True, linestyle='--', alpha=0.4)\n",
        "\n",
        "    # Plot 2: Enhanced pie chart\n",
        "    plant_totals = {p: plant_data[p][\"Healthy\"] + plant_data[p][\"Diseased\"] for p in plants}\n",
        "    wedges, texts, autotexts = ax2.pie(plant_totals.values(), labels=plant_totals.keys(),\n",
        "                                      autopct='%1.1f%%', startangle=90,\n",
        "                                      colors=pie_colors,\n",
        "                                      wedgeprops={'linewidth': 1.5, 'edgecolor': 'white'},\n",
        "                                      textprops={'fontsize': 11})\n",
        "\n",
        "    # Improve percentage formatting\n",
        "    for autotext in autotexts:\n",
        "        autotext.set_color('white')\n",
        "        autotext.set_fontweight('bold')\n",
        "\n",
        "    # Add donut effect\n",
        "    centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
        "    ax2.add_artist(centre_circle)\n",
        "\n",
        "    ax2.set_title('Image Distribution by Plant Type\\n',\n",
        "                 fontsize=16, fontweight='bold', color='#2E4053')\n",
        "\n",
        "    plt.tight_layout(pad=3.0)\n",
        "\n",
        "    # Summary statistics with enhanced formatting\n",
        "    total_images = sum(plant_totals.values())\n",
        "    total_healthy = sum(healthy_counts)\n",
        "    total_diseased = sum(diseased_counts)\n",
        "\n",
        "    print(f\"\\n{'ðŸ“Š'*3} Dataset Summary {'ðŸ“Š'*3}\")\n",
        "    print(f\"\\nðŸ”¸ Total images: \\033[1m{total_images:,}\\033[0m\")\n",
        "    print(f\"ðŸ”¸ Healthy samples: \\033[1m{total_healthy:,}\\033[0m ({total_healthy/total_images:.1%})\")\n",
        "    print(f\"ðŸ”¸ Diseased samples: \\033[1m{total_diseased:,}\\033[0m ({total_diseased/total_images:.1%})\")\n",
        "    print(f\"ðŸ”¸ Number of plant types: \\033[1m{len(plants)}\\033[0m\")\n",
        "    print(f\"ðŸ”¸ Number of disease categories: \\033[1m{len(folders) - len(healthy_counts)}\\033[0m\\n\")\n",
        "\n",
        "plot_dataset_distribution(\"/content/Plant Disease Dataset\")"
      ],
      "metadata": {
        "id": "yqFEzdtt4GPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_augmentations(data_dir, num_plants=3):\n",
        "    disease_folders = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))]\n",
        "    selected_folders = random.sample(disease_folders, min(num_plants, len(disease_folders)))\n",
        "\n",
        "    # Define augmentations to display like the training used one.\n",
        "    augmentations = [\n",
        "        (\"Original\", transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor()\n",
        "        ])),\n",
        "        (\"Horizontal Flip\", transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.RandomHorizontalFlip(p=1.0),\n",
        "            transforms.ToTensor()\n",
        "        ])),\n",
        "        (\"Rotation (30Â°)\", transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.RandomRotation(30),\n",
        "            transforms.ToTensor()\n",
        "        ])),\n",
        "        (\"Color Jitter\", transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "            transforms.ToTensor()\n",
        "        ])),\n",
        "        (\"Combined\", transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(20),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "            transforms.ToTensor()\n",
        "        ]))\n",
        "    ]\n",
        "\n",
        "    fig, axes = plt.subplots(len(selected_folders), len(augmentations), figsize=(18, 4 * len(selected_folders)))\n",
        "\n",
        "    for i, folder in enumerate(selected_folders):\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "\n",
        "        img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if not img_files:\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(folder_path, random.choice(img_files))\n",
        "        original_img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        for j, (aug_name, transform) in enumerate(augmentations):\n",
        "            img_tensor = transform(original_img)\n",
        "\n",
        "            img_np = img_tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "            ax = axes[i, j] if len(selected_folders) > 1 else axes[j]\n",
        "            ax.imshow(img_np)\n",
        "\n",
        "            if i == 0:\n",
        "                ax.set_title(aug_name, fontsize=12)\n",
        "\n",
        "            if j == 0:\n",
        "                disease_name = folder.replace('_', ' ')\n",
        "                ax.set_ylabel(disease_name, fontsize=10)\n",
        "\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(\"Data Augmentation Techniques for Plant Disease Images\", fontsize=20, y=1.0)\n",
        "    plt.show()\n",
        "\n",
        "show_augmentations(\"/content/Plant Disease Dataset\")"
      ],
      "metadata": {
        "id": "iqnRxkmS4kGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Evaluation Functions\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluate model on validation or test set\"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(enumerate(data_loader), desc=\"Evaluating\", total=len(data_loader))\n",
        "        for batch_idx, (inputs, labels) in progress_bar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            progress_bar.set_postfix({\"Val Loss\": loss.item(), \"Accuracy\": correct / total * 100})\n",
        "\n",
        "    val_loss /= len(data_loader)\n",
        "    accuracy = correct / total * 100\n",
        "    return val_loss, accuracy, np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler=None,\n",
        "                epochs=10, early_stopping=None, device=\"cpu\"):\n",
        "    \"\"\"Train the model with optional early stopping and learning rate scheduler\"\"\"\n",
        "    model.to(device)\n",
        "    train_losses, valid_losses, valid_accuracies = [], [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        progress_bar = tqdm(enumerate(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\",\n",
        "                           total=len(train_loader))\n",
        "\n",
        "        for batch_idx, (inputs, labels) in progress_bar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            progress_bar.set_postfix({\"Train Loss\": loss.item()})\n",
        "\n",
        "        # Record training loss\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Validation step\n",
        "        val_loss, val_accuracy, _, _ = evaluate_model(model, valid_loader, criterion, device)\n",
        "        valid_losses.append(val_loss)\n",
        "        valid_accuracies.append(val_accuracy)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, \"\n",
        "              f\"Val Accuracy = {val_accuracy:.2f}%\")\n",
        "\n",
        "        # Learning rate scheduler step\n",
        "        if scheduler:\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "        # Early stopping\n",
        "        if early_stopping and early_stopping(val_loss, model):\n",
        "            print(\"[INFO] Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Save the learning curves\n",
        "    save_learning_curves(train_losses, valid_losses, valid_accuracies)\n",
        "\n",
        "    return train_losses, valid_losses, valid_accuracies\n",
        "\n",
        "def save_learning_curves(train_losses, valid_losses, valid_accuracies):\n",
        "    \"\"\"Save learning curves as a plot\"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(valid_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    # Plot validation accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(valid_accuracies, label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.title('Validation Accuracy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('learning_curves.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "kCW6fzE35fua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction function for inference\n",
        "def predict_image(model, image_path, transform, device, label_encoder=None):\n",
        "    \"\"\"Make prediction on a single image\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Open and transform the image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "    predicted_idx = predicted.item()\n",
        "    confidence = probabilities[0][predicted_idx].item() * 100\n",
        "\n",
        "    if label_encoder:\n",
        "        predicted_class = label_encoder.inverse_transform([predicted_idx])[0]\n",
        "        return predicted_class, confidence, probabilities[0].cpu().numpy()\n",
        "    else:\n",
        "        return predicted_idx, confidence, probabilities[0].cpu().numpy()\n",
        "\n",
        "# Main function to train the model\n",
        "def train(data_dir, model_save_path=\"disease_model.pth\", batch_size=32,\n",
        "          epochs=30, learning_rate=0.001, image_size=(256, 256)):\n",
        "    \"\"\"Main function to train and save the model and necessary files for deployment\"\"\"\n",
        "    # Prepare data\n",
        "    train_loader, valid_loader, test_loader, num_classes = prepare_data(\n",
        "        data_dir, image_size=image_size, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # Setup device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Initialize model, loss function, optimizer and scheduler\n",
        "    model = PlantDiseaseModel(num_classes=num_classes, dropout_rate=0.5)\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.1, patience=3, verbose=True\n",
        "    )\n",
        "    early_stopping = EarlyStopping(patience=7, min_delta=0.001, save_path=model_save_path)\n",
        "\n",
        "    # Print model summary\n",
        "    print(f\"Model created with {num_classes} output classes\")\n",
        "\n",
        "    # Train the model\n",
        "    train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        valid_loader=valid_loader,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        epochs=epochs,\n",
        "        early_stopping=early_stopping,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Load the model\n",
        "    model.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\n[INFO] Evaluating the model on the test set...\")\n",
        "    test_loss, test_accuracy, predictions, true_labels = evaluate_model(\n",
        "        model, test_loader, criterion, device\n",
        "    )\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    # Save model architecture for inference\n",
        "    dummy_input = torch.randn(1, 3, *image_size).to(device)\n",
        "    torch.onnx.export(model, dummy_input, \"plant_disease_model.onnx\")\n",
        "\n",
        "    # Save model config\n",
        "    model_config = {\n",
        "        \"image_size\": image_size,\n",
        "        \"num_classes\": num_classes,\n",
        "        \"model_path\": model_save_path,\n",
        "        \"label_encoder_path\": \"label_encoder.pkl\",\n",
        "        \"transform_path\": \"inference_transform.pkl\",\n",
        "        \"class_names_path\": \"class_names.json\"\n",
        "    }\n",
        "\n",
        "    with open(\"model_config.json\", \"w\") as f:\n",
        "        json.dump(model_config, f)\n",
        "\n",
        "    print(\"[INFO] Training completed and all necessary files saved for deployment.\")\n",
        "    return model, model_config"
      ],
      "metadata": {
        "id": "uMv0x4MK5zbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    data_dir = \"/content/Plant Disease Dataset\"\n",
        "    model_path = \"disease_model.pth\"\n",
        "    batch_size = 32\n",
        "    epochs = 25\n",
        "    learning_rate = 0.0065\n",
        "\n",
        "    model, model_config = train(\n",
        "        data_dir=data_dir,\n",
        "        model_save_path=model_path,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        learning_rate=learning_rate\n",
        "    )"
      ],
      "metadata": {
        "id": "-CeSY5-n599_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_learning_curves():\n",
        "    try:\n",
        "        # Load training history if it exists\n",
        "        with open('learning_curves.png', 'rb') as f:\n",
        "            plt.figure(figsize=(12, 5))\n",
        "            img = plt.imread('learning_curves.png')\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "    except FileNotFoundError:\n",
        "        print(\"Learning curves not found. Train the model first.\")\n",
        "\n",
        "print(\"ðŸ“Š Visualizing Model Training Progress:\")\n",
        "visualize_learning_curves()"
      ],
      "metadata": {
        "id": "tGS9s3B972tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_by_plant_type(model, test_loader, label_encoder, device):\n",
        "    \"\"\"Evaluate model performance separately for each plant type with enhanced visualization\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare containers for per-class metrics\n",
        "    class_correct = {}\n",
        "    class_total = {}\n",
        "\n",
        "    # Get all predictions\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Store predictions and true labels\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Update per-class counts\n",
        "            for i, label in enumerate(labels):\n",
        "                label_idx = label.item()\n",
        "                label_name = label_encoder.inverse_transform([label_idx])[0]\n",
        "\n",
        "                if label_name not in class_correct:\n",
        "                    class_correct[label_name] = 0\n",
        "                    class_total[label_name] = 0\n",
        "\n",
        "                class_total[label_name] += 1\n",
        "                if preds[i] == label:\n",
        "                    class_correct[label_name] += 1\n",
        "\n",
        "    # Extract plant types from class names\n",
        "    plants = {}\n",
        "    for class_name in class_correct.keys():\n",
        "        if \"__\" in class_name:\n",
        "            plant = class_name.split(\"__\")[0].replace(\"_\", \" \")\n",
        "        else:\n",
        "            plant = class_name.split(\"_\")[0]\n",
        "\n",
        "        if plant not in plants:\n",
        "            plants[plant] = {\"correct\": 0, \"total\": 0}\n",
        "\n",
        "        plants[plant][\"correct\"] += class_correct[class_name]\n",
        "        plants[plant][\"total\"] += class_total[class_name]\n",
        "\n",
        "    # Compute accuracy per plant type\n",
        "    plant_accuracy = {p: (stats[\"correct\"] / stats[\"total\"]) * 100\n",
        "                     for p, stats in plants.items()}\n",
        "\n",
        "    # Sort plants by accuracy for better visual comparison\n",
        "    sorted_plants = dict(sorted(plant_accuracy.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    # Enhanced Visualization\n",
        "    plt.style.use('ggplot')\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    # Improved color configuration\n",
        "    colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(sorted_plants)))\n",
        "\n",
        "    # Calculate average accuracy\n",
        "    avg_accuracy = np.mean(list(plant_accuracy.values()))\n",
        "\n",
        "    # Create bars with enhanced styling\n",
        "    plants_list = list(sorted_plants.keys())\n",
        "    accuracies = list(sorted_plants.values())\n",
        "    totals = [plants[p][\"total\"] for p in plants_list]\n",
        "\n",
        "    # Create gradient background\n",
        "    ax.set_facecolor('#f8f9fa')\n",
        "    fig.patch.set_facecolor('#ffffff')\n",
        "\n",
        "    # Create enhanced bars\n",
        "    bars = ax.bar(plants_list, accuracies, color=colors, edgecolor='#505050',\n",
        "                 linewidth=1, alpha=0.85, width=0.7)\n",
        "\n",
        "    # Add drop shadow effect to bars\n",
        "    for bar in bars:\n",
        "        x, y = bar.get_xy()\n",
        "        w, h = bar.get_width(), bar.get_height()\n",
        "        shadow = plt.Rectangle((x+0.03, y-0.03), w, h, color='#00000022', zorder=0)\n",
        "        ax.add_patch(shadow)\n",
        "\n",
        "    # Add annotations with improved styling\n",
        "    for bar, acc, total in zip(bars, accuracies, totals):\n",
        "        height = bar.get_height()\n",
        "        # Add accuracy labels\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "               f'{acc:.1f}%',\n",
        "               ha='center', va='bottom',\n",
        "               fontsize=11, fontweight='bold',\n",
        "               bbox=dict(boxstyle=\"round,pad=0.3\", fc='white', ec=\"grey\", alpha=0.8))\n",
        "\n",
        "        # Add sample size labels\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height/2,\n",
        "               f'n={total}',\n",
        "               ha='center', va='center',\n",
        "               fontsize=10, color='#303030',\n",
        "               fontweight='bold', rotation=0)\n",
        "\n",
        "    # Add reference lines and styling\n",
        "    ax.axhline(avg_accuracy, color='#e74c3c', linestyle='-', linewidth=2.5, alpha=0.7)\n",
        "    ax.axhline(avg_accuracy, color='#c0392b', linestyle='-', linewidth=1, alpha=1)\n",
        "\n",
        "    # Add average line label with enhanced styling\n",
        "    ax.text(len(plants_list)-0.5, avg_accuracy + 3,\n",
        "           f' Average: {avg_accuracy:.1f}%',\n",
        "           color='#c0392b', fontsize=13, ha='right', va='bottom',\n",
        "           fontweight='bold',\n",
        "           bbox=dict(boxstyle=\"round,pad=0.3\", fc='white', ec=\"#c0392b\", alpha=0.8))\n",
        "\n",
        "    # Configure axes and labels with enhanced styling\n",
        "    ax.set_title(f'Model Accuracy by Plant Type\\n{model.__class__.__name__} Performance Analysis',\n",
        "                fontsize=18, pad=20, fontweight='bold', color='#2c3e50')\n",
        "\n",
        "    ax.set_xlabel('Plant Type', fontsize=14, labelpad=15, fontweight='bold', color='#2c3e50')\n",
        "    ax.set_ylabel('Accuracy (%)', fontsize=14, labelpad=15, fontweight='bold', color='#2c3e50')\n",
        "\n",
        "    # Add a subtle box around the plot\n",
        "    for spine in ax.spines.values():\n",
        "        spine.set_visible(True)\n",
        "        spine.set_color('#cccccc')\n",
        "        spine.set_linewidth(1)\n",
        "\n",
        "    # Enhanced tick parameters\n",
        "    ax.tick_params(axis='x', rotation=45, labelsize=12, pad=5, colors='#2c3e50')\n",
        "    ax.tick_params(axis='y', labelsize=12, pad=5, colors='#2c3e50')\n",
        "    ax.set_ylim(0, max(accuracies) * 1.15)\n",
        "\n",
        "    # Add customized grid\n",
        "    ax.yaxis.grid(True, linestyle='--', alpha=0.4, color='#95a5a6')\n",
        "    ax.set_axisbelow(True)\n",
        "\n",
        "    # Add a subtle top performance indicator\n",
        "    top_performer = plants_list[0]\n",
        "    top_accuracy = accuracies[0]\n",
        "    ax.text(0, max(accuracies) * 1.1,\n",
        "           f\"Top Performer: {top_performer} ({top_accuracy:.1f}%)\",\n",
        "           fontsize=12, ha='left', color='#27ae60',\n",
        "           bbox=dict(boxstyle=\"round,pad=0.3\", fc='#f8f9fa', ec=\"#2ecc71\", alpha=0.8))\n",
        "\n",
        "    # Add watermark or model info\n",
        "    fig.text(0.95, 0.02, f\"{model.__class__.__name__}\",\n",
        "             fontsize=10, color='gray', ha='right', va='bottom', alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return plant_accuracy"
      ],
      "metadata": {
        "id": "3Xif4_Li8OmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and necessary components\n",
        "model_path = \"disease_model.pth\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load class names and create model\n",
        "with open('class_names.json', 'r') as f:\n",
        "    class_names = json.load(f)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "model = PlantDiseaseModel(num_classes=num_classes)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device)\n",
        "\n",
        "# Load label encoder and transform\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "with open('inference_transform.pkl', 'rb') as f:\n",
        "    transform = pickle.load(f)\n",
        "\n",
        "print(f\"âœ… Model loaded with {num_classes} classes\")\n",
        "print(f\"âœ… Using device: {device}\")\n",
        "\n",
        "# Cell 3: Evaluate Model Performance by Plant Type\n",
        "data_dir = \"/content/Plant Disease Dataset\"\n",
        "batch_size = 32\n",
        "\n",
        "_, _, test_loader, _ = prepare_data(\n",
        "    data_dir,\n",
        "    image_size=(256, 256),\n",
        "    batch_size=batch_size,\n",
        "    test_size=0.3,\n",
        "    valid_ratio=0.5\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ“Š Evaluating model performance by plant type...\")\n",
        "plant_accuracy = evaluate_by_plant_type(model, test_loader, label_encoder, device)"
      ],
      "metadata": {
        "id": "5y3LJumm8lP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "xsUKZx9f9TiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_gradcam(model, img_path, transform, label_encoder, device, layer_name='conv_block5'):\n",
        "    try:\n",
        "        import cv2\n",
        "    except ImportError:\n",
        "        print(\"OpenCV (cv2) is required for Grad-CAM visualization. Please install it with: !pip install opencv-python\")\n",
        "        return\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Hook for the selected layer\n",
        "    activations = None\n",
        "    gradients = None\n",
        "\n",
        "    def forward_hook(module, input, output):\n",
        "        nonlocal activations\n",
        "        activations = output.detach()\n",
        "\n",
        "    def backward_hook(module, grad_input, grad_output):\n",
        "        nonlocal gradients\n",
        "        gradients = grad_output[0].detach()\n",
        "\n",
        "    # Register hooks\n",
        "    if layer_name == 'conv_block5':\n",
        "        target_layer = model.conv_block5[0]  # First conv layer of the last block\n",
        "    elif layer_name == 'conv_block4':\n",
        "        target_layer = model.conv_block4[0]\n",
        "    else:\n",
        "        target_layer = model.conv_block3[0]\n",
        "\n",
        "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "    backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    try:\n",
        "        # Load and preprocess image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        input_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_tensor)\n",
        "        pred_idx = output.argmax(dim=1).item()\n",
        "        pred_class = label_encoder.inverse_transform([pred_idx])[0]\n",
        "\n",
        "        # Backward pass for the predicted class\n",
        "        model.zero_grad()\n",
        "        output[:, pred_idx].backward()\n",
        "\n",
        "        # Generate Grad-CAM\n",
        "        if activations is not None and gradients is not None:\n",
        "            # Pool gradients across the channels\n",
        "            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
        "\n",
        "            # Weight activation maps by gradients\n",
        "            for i in range(activations.size(1)):\n",
        "                activations[:, i, :, :] *= pooled_gradients[i]\n",
        "\n",
        "            # Average over channels\n",
        "            heatmap = torch.mean(activations, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "            # ReLU on heatmap\n",
        "            heatmap = np.maximum(heatmap, 0)\n",
        "\n",
        "            # Normalize heatmap\n",
        "            if np.max(heatmap) > 0:\n",
        "                heatmap = heatmap / np.max(heatmap)\n",
        "\n",
        "            # Resize heatmap to original image size\n",
        "            original_img = np.array(img)\n",
        "            heatmap = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))\n",
        "\n",
        "            # Apply colormap to heatmap\n",
        "            heatmap = np.uint8(255 * heatmap)\n",
        "            heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "            # Superimpose heatmap on original image\n",
        "            superimposed = cv2.addWeighted(original_img, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "            # Create figure with original and heatmap\n",
        "            plt.figure(figsize=(15, 5))\n",
        "\n",
        "            # Plot original image\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.imshow(original_img)\n",
        "            plt.title(\"Original Image\", fontsize=14)\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Plot heatmap\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.imshow(cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB))\n",
        "            plt.title(\"Grad-CAM Heatmap\", fontsize=14)\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Plot superimposed\n",
        "            plt.subplot(1, 3, 3)\n",
        "            plt.imshow(cv2.cvtColor(superimposed, cv2.COLOR_BGR2RGB))\n",
        "            plt.title(f\"Prediction: {pred_class}\", fontsize=14)\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"Could not generate activations or gradients\")\n",
        "    finally:\n",
        "        # Always remove hooks to prevent memory leaks\n",
        "        forward_handle.remove()\n",
        "        backward_handle.remove()\n",
        "\n",
        "# Cell 5: Apply Grad-CAM to sample images\n",
        "def generate_gradcam_visualizations(num_samples=2):\n",
        "    print(\"\\nðŸ” Generating Grad-CAM visualizations...\")\n",
        "    sample_images = []\n",
        "\n",
        "    for disease_folder in os.listdir(data_dir):\n",
        "        disease_folder_path = os.path.join(data_dir, disease_folder)\n",
        "        if not os.path.isdir(disease_folder_path):\n",
        "            continue\n",
        "\n",
        "        img_files = [f for f in os.listdir(disease_folder_path)\n",
        "                    if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if img_files:\n",
        "            selected_img = os.path.join(disease_folder_path, random.choice(img_files))\n",
        "            sample_images.append((selected_img, disease_folder))\n",
        "\n",
        "    # Apply GradCAM to a couple of sample images\n",
        "    if sample_images:\n",
        "        samples_to_visualize = random.sample(sample_images, min(num_samples, len(sample_images)))\n",
        "        for i, (img_path, true_label) in enumerate(samples_to_visualize):\n",
        "            print(f\"\\nVisualizing sample {i+1} - {true_label}...\")\n",
        "            apply_gradcam(model, img_path, transform, label_encoder, device)\n",
        "    else:\n",
        "        print(\"No sample images found.\")\n",
        "\n",
        "# Generate visualizations for 2 random samples\n",
        "generate_gradcam_visualizations(num_samples=2)"
      ],
      "metadata": {
        "id": "9r_tJVFC8k69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_disease_diagnosis(model_path, label_encoder_path, transform_path, sample_images_dir):\n",
        "    \"\"\"\n",
        "    Create an interactive display showing disease diagnosis and treatment recommendations\n",
        "\n",
        "    Arguments:\n",
        "    model_path -- path to the trained model\n",
        "    label_encoder_path -- path to the saved label encoder\n",
        "    transform_path -- path to the saved transform\n",
        "    sample_images_dir -- directory containing sample images\n",
        "    \"\"\"\n",
        "    #libraries if error\n",
        "    from matplotlib.gridspec import GridSpec\n",
        "\n",
        "    # Load model\n",
        "    with open('class_names.json', 'r') as f:\n",
        "        class_names = json.load(f)\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    model = PlantDiseaseModel(num_classes=num_classes)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Load label encoder and transform\n",
        "    with open(label_encoder_path, 'rb') as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "\n",
        "    with open(transform_path, 'rb') as f:\n",
        "        transform = pickle.load(f)\n",
        "\n",
        "    # Treatment recommendations for common plant diseases\n",
        "    treatment_recommendations = {\n",
        "        \"Tomato_Bacterial_spot\": [\n",
        "            \"Remove and destroy infected plants\",\n",
        "            \"Rotate crops (avoid planting tomatoes in the same location for 2-3 years)\",\n",
        "            \"Use copper-based fungicides\",\n",
        "            \"Ensure proper spacing between plants for good air circulation\"\n",
        "        ],\n",
        "        \"Tomato_Early_blight\": [\n",
        "            \"Remove infected leaves immediately\",\n",
        "            \"Apply fungicides containing chlorothalonil or copper\",\n",
        "            \"Mulch around the base of plants\",\n",
        "            \"Water at soil level rather than on foliage\"\n",
        "        ],\n",
        "        \"Tomato_Late_blight\": [\n",
        "            \"Remove and destroy infected plants\",\n",
        "            \"Apply fungicides proactively before symptoms appear\",\n",
        "            \"Improve air circulation around plants\",\n",
        "            \"Avoid overhead irrigation\"\n",
        "        ],\n",
        "        \"Tomato_Leaf_Mold\": [\n",
        "            \"Increase spacing between plants to improve air circulation\",\n",
        "            \"Apply fungicides containing chlorothalonil or copper\",\n",
        "            \"Remove infected leaves\",\n",
        "            \"Keep foliage dry by watering at the base\"\n",
        "        ],\n",
        "        \"Tomato_Septoria_leaf_spot\": [\n",
        "            \"Remove infected leaves\",\n",
        "            \"Apply fungicides containing chlorothalonil or copper\",\n",
        "            \"Rotate crops\",\n",
        "            \"Mulch around plants to prevent spores splashing from soil\"\n",
        "        ],\n",
        "        \"Tomato_Spider_mites_Two_spotted_spider_mite\": [\n",
        "            \"Spray plants with strong streams of water to dislodge mites\",\n",
        "            \"Apply insecticidal soap or neem oil\",\n",
        "            \"Introduce predatory mites\",\n",
        "            \"Increase humidity around plants\"\n",
        "        ],\n",
        "        \"Tomato__Target_Spot\": [\n",
        "            \"Remove infected plant debris\",\n",
        "            \"Apply fungicides\",\n",
        "            \"Improve air circulation\",\n",
        "            \"Avoid overhead watering\"\n",
        "        ],\n",
        "        \"Tomato__Tomato_YellowLeaf__Curl_Virus\": [\n",
        "            \"No cure available - remove and destroy infected plants\",\n",
        "            \"Control whitefly populations (vectors)\",\n",
        "            \"Use reflective mulches to repel whiteflies\",\n",
        "            \"Plant resistant varieties\"\n",
        "        ],\n",
        "        \"Tomato__Tomato_mosaic_virus\": [\n",
        "            \"No cure available - remove and destroy infected plants\",\n",
        "            \"Wash hands and tools after handling infected plants\",\n",
        "            \"Control aphid populations (vectors)\",\n",
        "            \"Plant resistant varieties\"\n",
        "        ],\n",
        "        \"Potato___Early_blight\": [\n",
        "            \"Remove infected leaves\",\n",
        "            \"Apply fungicides containing chlorothalonil\",\n",
        "            \"Maintain good soil fertility\",\n",
        "            \"Ensure proper hilling to protect tubers\"\n",
        "        ],\n",
        "        \"Potato___Late_blight\": [\n",
        "            \"Apply fungicides preventatively\",\n",
        "            \"Remove volunteer potato plants\",\n",
        "            \"Harvest tubers during dry weather\",\n",
        "            \"Ensure proper storage conditions for harvested potatoes\"\n",
        "        ],\n",
        "        \"Pepper__bell___Bacterial_spot\": [\n",
        "            \"Remove infected plant debris\",\n",
        "            \"Rotate crops\",\n",
        "            \"Apply copper-based sprays\",\n",
        "            \"Use disease-free seeds\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Default recommendation for healthy plants\n",
        "    default_healthy_practices = [\n",
        "        \"Maintain proper watering schedule\",\n",
        "        \"Ensure adequate sunlight\",\n",
        "        \"Fertilize appropriately for plant type\",\n",
        "        \"Monitor regularly for signs of disease\"\n",
        "    ]\n",
        "\n",
        "    # Helper function for prediction\n",
        "    def predict_image(model, img_path, transform, device, label_encoder):\n",
        "        # Load and preprocess image\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        # Get prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = model(image_tensor)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
        "\n",
        "        # Get top prediction\n",
        "        top_prob, top_class = torch.max(probabilities, 0)\n",
        "        predicted_class = label_encoder.inverse_transform([top_class.item()])[0]\n",
        "        confidence = float(top_prob.item()) * 100\n",
        "\n",
        "        return predicted_class, confidence, probabilities.cpu().numpy()\n",
        "\n",
        "    # Find test images\n",
        "    test_images = []\n",
        "    for disease_folder in os.listdir(sample_images_dir):\n",
        "        disease_folder_path = os.path.join(sample_images_dir, disease_folder)\n",
        "        if not os.path.isdir(disease_folder_path):\n",
        "            continue\n",
        "\n",
        "        img_files = [f for f in os.listdir(disease_folder_path)\n",
        "                    if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if img_files:\n",
        "            # Take a random image from this disease category\n",
        "            selected_img = os.path.join(disease_folder_path, random.choice(img_files))\n",
        "            test_images.append((selected_img, disease_folder))\n",
        "\n",
        "    # Randomly select images for demonstration\n",
        "    num_images = min(6, len(test_images))  # Increased from 4 to 6 images\n",
        "    selected_test_images = random.sample(test_images, num_images) if len(test_images) > num_images else test_images\n",
        "\n",
        "    # Set up the figure with GridSpec for better layout control\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "    fig = plt.figure(figsize=(24, 20))\n",
        "    gs = GridSpec(3, 2, figure=fig)\n",
        "\n",
        "    # Add a stylish title with improved formatting\n",
        "    fig.suptitle(\"ðŸŒ¿ Plant Disease Diagnosis & Treatment Recommendations\",\n",
        "                 fontsize=28, fontweight='bold', y=0.98,\n",
        "                 bbox=dict(facecolor='#e8f4ea', edgecolor='green', boxstyle='round,pad=0.5'))\n",
        "\n",
        "    # Add a subtitle with system info\n",
        "    fig.text(0.5, 0.94, f\"Running on: {device} | Model: PlantDiseaseModel | Classes: {num_classes}\",\n",
        "             ha='center', fontsize=14, fontstyle='italic', color='#555555')\n",
        "\n",
        "    # Color palette for recommendations\n",
        "    treatment_colors = {\n",
        "        'healthy': '#e8f4ea',  # Light green\n",
        "        'disease': '#f9e8ea'   # Light red\n",
        "    }\n",
        "\n",
        "    # Add a legend for confidence\n",
        "    cmap = plt.cm.RdYlGn\n",
        "    confidence_gradient = np.linspace(0, 1, 100)\n",
        "    confidence_bar = np.vstack((confidence_gradient, confidence_gradient))\n",
        "\n",
        "    # Add confidence colorbar at the bottom\n",
        "    cax = fig.add_axes([0.3, 0.05, 0.4, 0.02])\n",
        "    cb = plt.colorbar(plt.imshow(confidence_bar, cmap=cmap), cax=cax, orientation='horizontal')\n",
        "    cb.set_label('Prediction Confidence', fontsize=14)\n",
        "    cb.set_ticks([0, 0.25, 0.5, 0.75, 1])\n",
        "    cb.set_ticklabels(['0%', '25%', '50%', '75%', '100%'])\n",
        "\n",
        "    # Create grid layout based on number of images\n",
        "    rows = 2 if num_images <= 4 else 3\n",
        "    cols = 2\n",
        "\n",
        "    # Process each selected image\n",
        "    all_predictions = []  # Store prediction results\n",
        "    for i, (img_path, true_label) in enumerate(selected_test_images):\n",
        "        if i >= rows * cols:\n",
        "            break\n",
        "\n",
        "        # Calculate grid position\n",
        "        row = i // cols\n",
        "        col = i % cols\n",
        "\n",
        "        # Make prediction\n",
        "        predicted_class, confidence, probabilities = predict_image(\n",
        "            model, img_path, transform, device, label_encoder)\n",
        "\n",
        "        # Store prediction result\n",
        "        all_predictions.append((os.path.basename(img_path), true_label, predicted_class, confidence))\n",
        "\n",
        "        # Create subplot with better positioning\n",
        "        ax = fig.add_subplot(gs[row, col])\n",
        "\n",
        "        # Load and display image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Determine if prediction is correct\n",
        "        is_correct = predicted_class == true_label\n",
        "\n",
        "        # Format disease name for display\n",
        "        display_pred = predicted_class.replace('_', ' ')\n",
        "        display_true = true_label.replace('_', ' ')\n",
        "\n",
        "        # Apply color based on confidence\n",
        "        title_color = cmap(confidence/100)\n",
        "\n",
        "        # Create a styled title box\n",
        "        title_box = dict(\n",
        "            boxstyle='round,pad=0.5',\n",
        "            facecolor=cmap(confidence/100),\n",
        "            alpha=0.8,\n",
        "            edgecolor='gray'\n",
        "        )\n",
        "\n",
        "        # Set title with prediction info in a box\n",
        "        ax.set_title(f\"Prediction: {display_pred}\\nConfidence: {confidence:.1f}%\",\n",
        "                    fontsize=16, fontweight='bold', color='white',\n",
        "                    bbox=title_box)\n",
        "\n",
        "        # Add actual label in smaller text\n",
        "        ax.text(0.5, -0.05, f\"Actual: {display_true}\",\n",
        "                transform=ax.transAxes, ha='center', fontsize=14,\n",
        "                color='black' if is_correct else 'darkred',\n",
        "                fontweight='bold' if not is_correct else 'normal')\n",
        "\n",
        "        # Get treatment recommendations\n",
        "        is_healthy = \"healthy\" in predicted_class.lower()\n",
        "        if is_healthy:\n",
        "            recommendations = default_healthy_practices\n",
        "            recommendation_title = \"Healthy Plant Care:\"\n",
        "            box_color = treatment_colors['healthy']\n",
        "        else:\n",
        "            recommendations = treatment_recommendations.get(\n",
        "                predicted_class, [\"No specific recommendations available\"])\n",
        "            recommendation_title = \"Treatment Recommendations:\"\n",
        "            box_color = treatment_colors['disease']\n",
        "\n",
        "        # Create a styled box for recommendations\n",
        "        rec_box_props = dict(\n",
        "            boxstyle='round,pad=0.6',\n",
        "            facecolor=box_color,\n",
        "            alpha=0.85,\n",
        "            edgecolor='gray'\n",
        "        )\n",
        "\n",
        "        # Add disease severity indicator\n",
        "        if not is_healthy:\n",
        "            severity = \"High\" if confidence > 85 else \"Medium\" if confidence > 65 else \"Low\"\n",
        "            severity_color = \"red\" if severity == \"High\" else \"orange\" if severity == \"Medium\" else \"green\"\n",
        "            severity_text = f\"Severity: {severity}\"\n",
        "        else:\n",
        "            severity_text = \"Status: Healthy\"\n",
        "            severity_color = \"green\"\n",
        "\n",
        "        # Build recommendation text with formatting\n",
        "        recommendation_text = f\"{recommendation_title}\\n\"\n",
        "        for rec in recommendations:\n",
        "            recommendation_text += f\"â€¢ {rec}\\n\"\n",
        "\n",
        "        recommendation_text += f\"\\n{severity_text}\"\n",
        "\n",
        "        # Place recommendations in a better position\n",
        "        plt.figtext(0.5 + col * 0.5 - 0.48,\n",
        "                   0.9 - row * 0.33 - 0.13,\n",
        "                   recommendation_text,\n",
        "                   fontsize=14,\n",
        "                   color='black',\n",
        "                   bbox=rec_box_props,\n",
        "                   verticalalignment='top')\n",
        "\n",
        "        # Add severity indicator dot\n",
        "        plt.figtext(0.5 + col * 0.5 - 0.15,\n",
        "                   0.9 - row * 0.33 - 0.33,\n",
        "                   \"â—\",\n",
        "                   fontsize=30,\n",
        "                   color=severity_color,\n",
        "                   ha='right')\n",
        "\n",
        "        # Add top 3 probable diseases as small text (if not healthy)\n",
        "        if not is_healthy and len(class_names) > 1:\n",
        "            # Get top 3 predictions\n",
        "            top_indices = np.argsort(probabilities)[-3:][::-1]\n",
        "            top_classes = [label_encoder.inverse_transform([idx])[0].replace('_', ' ') for idx in top_indices]\n",
        "            top_probs = [probabilities[idx] * 100 for idx in top_indices]\n",
        "\n",
        "            # Format alternatives text\n",
        "            alt_text = \"Alternative diagnoses:\\n\"\n",
        "            for j, (cls, prob) in enumerate(zip(top_classes, top_probs)):\n",
        "                if j == 0:  # Skip the top prediction (already shown)\n",
        "                    continue\n",
        "                alt_text += f\"{cls}: {prob:.1f}%\\n\"\n",
        "\n",
        "            # Add alternatives in small text\n",
        "            plt.figtext(0.5 + col * 0.5 - 0.48,\n",
        "                       0.9 - row * 0.33 - 0.3,\n",
        "                       alt_text,\n",
        "                       fontsize=10,\n",
        "                       color='#555555',\n",
        "                       verticalalignment='top')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.08, 1, 0.93])\n",
        "\n",
        "    # Add a footer with additional information\n",
        "    footer_text = (\n",
        "        \"Note: This is an AI-assisted diagnosis tool and should be used as a guide only. \"\n",
        "        \"For conclusive diagnosis, consult with a professional plant pathologist.\"\n",
        "    )\n",
        "    fig.text(0.5, 0.01, footer_text, ha='center', fontsize=12, fontstyle='italic')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Return results summary for further use if needed\n",
        "    results = {\n",
        "        \"images_analyzed\": len(selected_test_images),\n",
        "        \"predictions\": all_predictions,\n",
        "        \"model_device\": str(device)\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"\\nðŸŒ¿ Running interactive disease diagnosis with treatment recommendations...\")\n",
        "results = interactive_disease_diagnosis(\n",
        "    model_path=model_path,\n",
        "    label_encoder_path=\"label_encoder.pkl\",\n",
        "    transform_path=\"inference_transform.pkl\",\n",
        "    sample_images_dir=data_dir\n",
        ")\n",
        "\n",
        "# Print a summary of results\n",
        "print(f\"\\nAnalysis complete! Examined {results['images_analyzed']} plant images\")\n",
        "print(f\"Model running on: {results['model_device']}\")\n",
        "print(\"\\nSummary of diagnoses:\")\n",
        "for img, true, pred, conf in results['predictions']:\n",
        "    match = \"âœ“\" if true.replace(\"_\", \" \") == pred.replace(\"_\", \" \") else \"âœ—\"\n",
        "    print(f\"- {img}: {pred.replace('_', ' ')} ({conf:.1f}%) {match}\")"
      ],
      "metadata": {
        "id": "8EFqIIzD8kht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KuX6vvoY5hvL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}